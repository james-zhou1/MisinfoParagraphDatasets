{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12406\\AppData\\Local\\Temp\\ipykernel_9608\\216391889.py:7: DtypeWarning: Columns (1,8,10,11,13,14,15,17,18,27,37,38,63,65,81,114,148,158,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../datasets/3_data_paragraph_labelled_prepared.csv', encoding='utf-8', encoding_errors='replace')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('../datasets/3_data_paragraph_labelled_prepared.csv', encoding='utf-8', encoding_errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128213"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>positive_evidence_text</th>\n",
       "      <th>positive_evidence_title</th>\n",
       "      <th>negative_evidence_text</th>\n",
       "      <th>negative_evidence_title</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>evidence_type</th>\n",
       "      <th>is_auth</th>\n",
       "      <th>evidence_id</th>\n",
       "      <th>evidence_label</th>\n",
       "      <th>article</th>\n",
       "      <th>evidence</th>\n",
       "      <th>entropy</th>\n",
       "      <th>Misinfo_type</th>\n",
       "      <th>speaker</th>\n",
       "      <th>veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake_news_corpus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake_news_corpus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake_news_corpus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake_news_corpus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake_news_corpus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim       label  question  answer  positive_evidence_text  \\\n",
       "0    NaN  unreliable       NaN     NaN                     NaN   \n",
       "1    NaN        fake       NaN     NaN                     NaN   \n",
       "2    NaN  unreliable       NaN     NaN                     NaN   \n",
       "3    NaN  unreliable       NaN     NaN                     NaN   \n",
       "4    NaN   clickbait       NaN     NaN                     NaN   \n",
       "\n",
       "   positive_evidence_title  negative_evidence_text  negative_evidence_title  \\\n",
       "0                      NaN                     NaN                      NaN   \n",
       "1                      NaN                     NaN                      NaN   \n",
       "2                      NaN                     NaN                      NaN   \n",
       "3                      NaN                     NaN                      NaN   \n",
       "4                      NaN                     NaN                      NaN   \n",
       "\n",
       "  split           dataset  ... evidence_type is_auth evidence_id  \\\n",
       "0   NaN  fake_news_corpus  ...           NaN     NaN         NaN   \n",
       "1   NaN  fake_news_corpus  ...           NaN     NaN         NaN   \n",
       "2   NaN  fake_news_corpus  ...           NaN     NaN         NaN   \n",
       "3   NaN  fake_news_corpus  ...           NaN     NaN         NaN   \n",
       "4   NaN  fake_news_corpus  ...           NaN     NaN         NaN   \n",
       "\n",
       "  evidence_label article evidence entropy Misinfo_type speaker  veracity  \n",
       "0            NaN     NaN      NaN     NaN          NaN     NaN         2  \n",
       "1            NaN     NaN      NaN     NaN          NaN     NaN         2  \n",
       "2            NaN     NaN      NaN     NaN          NaN     NaN         2  \n",
       "3            NaN     NaN      NaN     NaN          NaN     NaN         2  \n",
       "4            NaN     NaN      NaN     NaN          NaN     NaN         3  \n",
       "\n",
       "[5 rows x 233 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fa_kes' 'banfakenews' 'isot_fake_news' 'ti_cnn']\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('dataset')\n",
    "\n",
    "# Filter out groups where 'data_column' is completely NaN\n",
    "groups_with_data = grouped.filter(lambda x: x['date'].notna().any())\n",
    "\n",
    "# Extract distinct categories with data\n",
    "categories_with_data = groups_with_data['dataset'].unique()\n",
    "\n",
    "print(categories_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa_kes: 804 entries\n",
      "banfakenews: 58478 entries\n",
      "isot_fake_news: 44898 entries\n",
      "ti_cnn: 20015 entries\n"
     ]
    }
   ],
   "source": [
    "# Print number of entries for each dataset that has date information\n",
    "for category in categories_with_data:\n",
    "    count = len(groups_with_data[groups_with_data['dataset'] == category])\n",
    "    print(f\"{category}: {count} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124195\n"
     ]
    }
   ],
   "source": [
    "df_with_date = df[df.dataset.isin(['fa_kes', 'banfakenews', 'isot_fake_news', 'ti_cnn'])]\n",
    "print(len(df_with_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa_kes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.539     0.574     0.556       108\n",
      "           2      0.465     0.430     0.447        93\n",
      "\n",
      "    accuracy                          0.507       201\n",
      "   macro avg      0.502     0.502     0.501       201\n",
      "weighted avg      0.505     0.507     0.506       201\n",
      "\n",
      "banfakenews\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     1.000     1.000     13967\n",
      "           2      0.936     1.000     0.967        44\n",
      "\n",
      "    accuracy                          1.000     14011\n",
      "   macro avg      0.968     1.000     0.983     14011\n",
      "weighted avg      1.000     1.000     1.000     14011\n",
      "\n",
      "isot_fake_news\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.874     0.736     0.799      1389\n",
      "           2      0.937     0.974     0.955      5648\n",
      "\n",
      "    accuracy                          0.927      7037\n",
      "   macro avg      0.906     0.855     0.877      7037\n",
      "weighted avg      0.925     0.927     0.925      7037\n",
      "\n",
      "ti_cnn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.431     0.988     0.600       173\n",
      "           2      0.999     0.927     0.962      3117\n",
      "\n",
      "    accuracy                          0.931      3290\n",
      "   macro avg      0.715     0.958     0.781      3290\n",
      "weighted avg      0.969     0.931     0.943      3290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dset in ['fa_kes', 'banfakenews', 'isot_fake_news', 'ti_cnn']:\n",
    "  print(dset)\n",
    "\n",
    "  temp_df = df_with_date[df_with_date.dataset == dset]\n",
    "#   print(len(temp_df))\n",
    "  #temp_df.veracity = temp_df.label.map({'FALSE':2, 'TRUE':1, 'MOSTLY FALSE':2, 'MOSTLY TRUE':1})\n",
    "  temp_df = temp_df[temp_df.veracity != 3]\n",
    "  temp_df = temp_df[temp_df.veracity.notna()]\n",
    "  temp_df['veracity'] = temp_df['veracity'].astype(int)\n",
    "#   print(len(temp_df))\n",
    "  temp_df = temp_df[temp_df.date.notna()]\n",
    "#   print(len(temp_df))\n",
    "\n",
    "  temp_df['dates'] = pd.to_datetime(temp_df['date'], format='mixed')\n",
    "\n",
    "  # Find the earliest (minimum) date in the column\n",
    "  earliest_date = temp_df['dates'].min()\n",
    "\n",
    "  # Calculate the time since the earliest date in days\n",
    "  temp_df['time_since_first'] = ((temp_df['dates'] - earliest_date).dt.total_seconds() / (60 * 60 * 24)).astype(int)\n",
    "\n",
    "  # Convert the differences to float values\n",
    "  temp_df['time_since_first'] = temp_df['time_since_first'].astype(float)\n",
    "#   print(len(temp_df))\n",
    "\n",
    "  clf = RandomForestClassifier(max_depth=20, random_state=0)#, class_weight='balanced')\n",
    "\n",
    "  train, test = train_test_split(temp_df, test_size=0.25, random_state=42)\n",
    "\n",
    "  clf.fit(train.time_since_first.values.reshape(-1,1), train.veracity.values)\n",
    "  preds = clf.predict(test.time_since_first.values.reshape(-1,1))\n",
    "  true = test.veracity.values\n",
    "  print(classification_report(preds,true, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "127hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
